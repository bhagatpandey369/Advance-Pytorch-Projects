{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Reshape, Flatten\n",
    "from keras.layers import Dense, BatchNormalization, Conv2D, Conv2DTranspose, LeakyReLU, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed when invoked directly\n",
      "welcome to GAN coding\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Argument(s) not recognized: {'lr': 0.01}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 128\u001b[0m\n\u001b[0;32m    126\u001b[0m gan1 \u001b[38;5;241m=\u001b[39m GAN_1()\n\u001b[0;32m    127\u001b[0m trainX \u001b[38;5;241m=\u001b[39m gan1\u001b[38;5;241m.\u001b[39mpreprocess_real_part_training_dataset(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m--> 128\u001b[0m d_model \u001b[38;5;241m=\u001b[39m gan1\u001b[38;5;241m.\u001b[39mdefine_descriminator(input_shape\u001b[38;5;241m=\u001b[39mimg_shape1)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# visualkeras.layered_view(d_model)\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# visualkeras.layered_view(d_model, legend=True)\u001b[39;00m\n\u001b[0;32m    131\u001b[0m g_model \u001b[38;5;241m=\u001b[39m gan1\u001b[38;5;241m.\u001b[39mdefine_generator(latent_dim\u001b[38;5;241m=\u001b[39mlatent_dim1, img_shape\u001b[38;5;241m=\u001b[39mimg_shape1)\n",
      "Cell \u001b[1;32mIn[6], line 69\u001b[0m, in \u001b[0;36mGAN_1.define_descriminator\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m     67\u001b[0m d_model \u001b[38;5;241m=\u001b[39m Model(inputs, discriminator_decision_layer)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# compile model\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m d_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mAdam(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     70\u001b[0m d_model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d_model\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\adam.py:62\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[1;34m(self, learning_rate, beta_1, beta_2, epsilon, amsgrad, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     45\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     61\u001b[0m ):\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     63\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m     64\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m     65\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m     66\u001b[0m         clipnorm\u001b[38;5;241m=\u001b[39mclipnorm,\n\u001b[0;32m     67\u001b[0m         clipvalue\u001b[38;5;241m=\u001b[39mclipvalue,\n\u001b[0;32m     68\u001b[0m         global_clipnorm\u001b[38;5;241m=\u001b[39mglobal_clipnorm,\n\u001b[0;32m     69\u001b[0m         use_ema\u001b[38;5;241m=\u001b[39muse_ema,\n\u001b[0;32m     70\u001b[0m         ema_momentum\u001b[38;5;241m=\u001b[39mema_momentum,\n\u001b[0;32m     71\u001b[0m         ema_overwrite_frequency\u001b[38;5;241m=\u001b[39mema_overwrite_frequency,\n\u001b[0;32m     72\u001b[0m         loss_scale_factor\u001b[38;5;241m=\u001b[39mloss_scale_factor,\n\u001b[0;32m     73\u001b[0m         gradient_accumulation_steps\u001b[38;5;241m=\u001b[39mgradient_accumulation_steps,\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     75\u001b[0m     )\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_1 \u001b[38;5;241m=\u001b[39m beta_1\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_2 \u001b[38;5;241m=\u001b[39m beta_2\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\optimizer.py:22\u001b[0m, in \u001b[0;36mTFOptimizer.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:37\u001b[0m, in \u001b[0;36mBaseOptimizer.__init__\u001b[1;34m(self, learning_rate, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `decay` is no longer supported and will be ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m     )\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument(s) not recognized: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     name \u001b[38;5;241m=\u001b[39m auto_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Argument(s) not recognized: {'lr': 0.01}"
     ]
    }
   ],
   "source": [
    "# example of training a gan on mnist\n",
    "from numpy import expand_dims\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Reshape, Flatten\n",
    "from keras.layers import Dense, BatchNormalization, Conv2D, Conv2DTranspose, LeakyReLU, Dropout\n",
    "batch_size = 32\n",
    "input_shape = (28, 28, 1)\n",
    "latent_dim = 100\n",
    "img_shape = (28, 28, 1)\n",
    "class GAN_1:\n",
    "  def __init__(self):\n",
    "    print(\"welcome to GAN coding\")\n",
    "  # This code prepares a TensorFlow dataset for training by shuffling the data, batching it into\n",
    "  # consistent batch sizes, and prefetching batches to optimize data loading during training.\n",
    "  def preprocess_real_part_training_dataset(self, batch_size):\n",
    "    # load mnist dataset\n",
    "    (dataX, dataY), (testDX, testDY) = keras.datasets.fashion_mnist.load_data()\n",
    "    # Add an additional dimension for the grayscale channel by using  expand_dims() from NumPy\n",
    "    dataX = expand_dims(dataX, axis=-1)\n",
    "    # convert from unsigned ints to floats and scale from [0,255] to [0,1]\n",
    "    dataX = dataX.astype(np.float32) / 255.0\n",
    "    # testDX = testDX.astype(np.float32) / 255.0\n",
    "    trainX = tf.data.Dataset.from_tensor_slices(dataX).shuffle(1000)\n",
    "    # Combines consecutive elements of this dataset into batches.\n",
    "    trainX = trainX.batch(batch_size, drop_remainder=True).prefetch(1)\n",
    "    return trainX\n",
    "\n",
    "  # latent_dim = 100\n",
    "  # img_shape = (28, 28, 1)\n",
    "  def define_generator(self, latent_dim, img_shape):\n",
    "      inputs = Input(shape=latent_dim)\n",
    "      # Project and reshape the input\n",
    "      proj = Dense(128 * 7 * 7)(inputs)\n",
    "      proj = Reshape((7, 7, 128))(proj)\n",
    "      # Upsample to 14x14\n",
    "      upsample_1 = Conv2DTranspose(filters=128, kernel_size=4, strides=2, padding='same', activation=LeakyReLU(alpha=0.2),)(proj)\n",
    "      upsample_1 = BatchNormalization()(upsample_1)\n",
    "      # Upsample to 28x28\n",
    "      upsample_2 = Conv2DTranspose(filters=128, kernel_size=4, strides=2, padding='same', activation=LeakyReLU(alpha=0.2),)(upsample_1)\n",
    "      upsample_2 = BatchNormalization()(upsample_2)\n",
    "      # Generate output image (28x28x1)\n",
    "      gen_output = Conv2D(filters=img_shape[2], kernel_size=7, activation='sigmoid', padding='same')(upsample_2)\n",
    "      g_model = Model(inputs, gen_output)\n",
    "      # compile model\n",
    "      g_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.01, beta_1=0.5), metrics=['accuracy'])\n",
    "      g_model.summary()\n",
    "      return g_model\n",
    "\n",
    "  # input_shape = (28, 28, 1)\n",
    "  def define_descriminator(self, input_shape):\n",
    "      inputs = Input(shape=input_shape)\n",
    "      # convolution layers\n",
    "      conv1 = Conv2D(filters=64, kernel_size=3, strides=2, activation=LeakyReLU(alpha=0.2), padding='same')(inputs)\n",
    "      conv1 = Dropout(0.4)(conv1)\n",
    "      conv1 = Conv2D(filters=128, kernel_size=3, strides=2, activation=LeakyReLU(alpha=0.2), padding='same')(conv1)\n",
    "      conv1 = Dropout(0.4)(conv1)\n",
    "      conv1 = Conv2D(filters=256, kernel_size=3, strides=2, activation=LeakyReLU(alpha=0.2), padding='same')(conv1)\n",
    "      conv1 = Dropout(0.4)(conv1)\n",
    "      # Flatten Layer\n",
    "      flatten_layer = Flatten()(conv1)\n",
    "      discriminator_decision_layer = Dense(1, activation='sigmoid')(flatten_layer)\n",
    "      d_model = Model(inputs, discriminator_decision_layer)\n",
    "      # compile model\n",
    "      d_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.01, beta_1=0.5), metrics=['accuracy'])\n",
    "      d_model.summary()\n",
    "      return d_model\n",
    "\n",
    "  def define_gan(self,latent_dim0, img_shape0):\n",
    "      # Define the input for the generator\n",
    "      latent_input = Input(shape=(latent_dim0,))\n",
    "      # Build the generator\n",
    "      generator_output = self.define_generator(latent_dim=latent_dim0,img_shape=img_shape0)(latent_input)\n",
    "      # Build the discriminator\n",
    "      discriminator_input = Input(shape=img_shape0)\n",
    "      discriminator_output = self.define_descriminator(input_shape=img_shape0)(discriminator_input)\n",
    "      # Compile the discriminator\n",
    "      discriminator = Model(discriminator_input, discriminator_output)\n",
    "      discriminator.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=0.01, beta_1=0.5))\n",
    "      # Make the discriminator not trainable\n",
    "      discriminator.trainable = False\n",
    "      # Combine the generator and discriminator\n",
    "      gan_output = discriminator(generator_output)\n",
    "      gan_model = Model(latent_input, gan_output)\n",
    "      # Compile the GAN\n",
    "      gan_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "      gan_model.summary()\n",
    "      return gan_model\n",
    "\n",
    "  def train_save_models(self, input_shape, latent_dim, img_shape, n_epochs=2, n_batch=256):\n",
    "      # manually enumerate epochs\n",
    "      g_model = self.define_generator(latent_dim=latent_dim,img_shape=img_shape)\n",
    "      d_model = self.define_descriminator(input_shape)\n",
    "      gan_main = self.define_gan(latent_dim0=latent_dim,img_shape0=img_shape)\n",
    "      for i in tqdm(range(n_epochs)):\n",
    "          print()\n",
    "          print(\"Epoch {}/{}\".format(i + 1, n_epochs))\n",
    "          # enumerate batches over the training set\n",
    "          for X_batch in trainX:\n",
    "              # generate  random noise as an input  to  initialize the  generator\n",
    "              noise = tf.random.normal(shape=[batch_size, latent_dim])\n",
    "              generated_images = g_model(noise)\n",
    "              # print(\"shape of noise => \",np.shape(noise))\n",
    "              X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
    "              y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "              d_loss = d_model.train_on_batch(x=X_fake_and_real,y=y1)\n",
    "              noise1 = tf.random.normal(shape=[batch_size, latent_dim])\n",
    "              # print(\"shape of noise1 => \", np.shape(noise1))\n",
    "              y2 = tf.constant([[1.]] * batch_size)\n",
    "              gan_loss = gan_main.train_on_batch(noise1, y2)\n",
    "              print(\"discriminator loss =>\",d_loss, \" Gan-Loss => \",gan_loss)\n",
    "      g_model.save(\"g_model.h5\")\n",
    "      d_model.save(\"d_model.h5\")\n",
    "      gan_main.save(\"gan_model.h5\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print (\"Executed when invoked directly\")\n",
    "    input_shape1 = (28, 28, 1)\n",
    "    img_shape1 = (28, 28, 1)\n",
    "    latent_dim1 = 100\n",
    "    # Create some dog objects\n",
    "    gan1 = GAN_1()\n",
    "    trainX = gan1.preprocess_real_part_training_dataset(batch_size=32)\n",
    "    d_model = gan1.define_descriminator(input_shape=img_shape1)\n",
    "    # visualkeras.layered_view(d_model)\n",
    "    # visualkeras.layered_view(d_model, legend=True)\n",
    "    g_model = gan1.define_generator(latent_dim=latent_dim1, img_shape=img_shape1)\n",
    "    gan_model = gan1.define_gan(latent_dim0=latent_dim1,img_shape0=img_shape1)\n",
    "    gan1.train_save_models(input_shape=input_shape1,latent_dim=latent_dim1, img_shape=img_shape1,n_epochs=50,n_batch=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
